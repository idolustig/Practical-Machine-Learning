---
title: "Quantified Self Movement Data Analysis"
author: "Ido Lustig"
date: "September 21, 2015"
output: html_document
---

## Introduction  
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  

This analysts, is aimed at using data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants for predicting how (well) the exercise was done.  

## Data Preprocessing  
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
```

#### Downloading the data  
```{r}
trainURL <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingFile <- "./data/pml-training.csv"
testingFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {dir.create("./data")}
if (!file.exists(trainingFile)) {download.file(trainURL, destfile=trainingFile)}
if (!file.exists(testingFile)) {download.file(testURL, destfile=testingFile)}
```  

#### Reading the data  
After downloading the data from the data source, we can read the two csv files into two data frames.  
```{r}
trainData <- read.csv("./data/pml-training.csv", na.strings=c("NA","#DIV/0!",""))
#actual final 'submission' file
testData <- read.csv("./data/pml-testing.csv", na.strings=c("NA","#DIV/0!","")) 
dim(trainData); dim(testData)
```
We will use only the `trainData` for training the model (breaking it into train and test later on). `testData` is going to serve us only at the end if the file for submitting our predictions in the Coursera site.  
The training data contains 19,622 observations and 160 variables; the `classe` variable in the training set is the outcome for prediction.  

#### Data cleansing  
Out of the 160 variables, some are 'dirty' (NA et-al) and some redundant (e.g. the timestamp the exercise was done). We're aiming to clean the data so it will be good for training a model.  
```{r}
classe <- trainData$classe #keep the classe for later
trainData <- trainData[, colSums(is.na(trainData)) == 0] #remove coulnms with missing data
#remove columns with timestamp or window in their name
trainData <- trainData[, !grepl("^X|timestamp|window", names(trainData))]
trainData <- trainData[, sapply(trainData, is.numeric)] #remove non-numerical columns
trainData$classe <- classe #re-add the classe variable
dim(trainData)
```
We're left with only 53 variables (one of which is `classe`).  

#### Data slicing  
Next, we split the clean data, into training (60% of the original training set) and testing (the remaining 40%).  
```{r}
set.seed(1978)
inTrain <- createDataPartition(trainData$classe, p=0.60, list=F)
training<- trainData[inTrain, ]
testing <- trainData[-inTrain, ]
dim(testing); dim(training)
```

## Data Modeling  
The chosen model for this exercise is Random Forest with 4-fold cross validation for 3 reasons: first, as it preforms self-feature selections, second since it deals well with outliers and correlated covariates, and third as I have never trained it until now...  
```{r}
trainControl <- trainControl(method="cv", number=4)
fit <- train(classe ~ ., data=training, method="rf", trControl=trainControl)
fit
```

Validating the performance on the training data:  
```{r}
predictRf <- predict(fit, testing)
confusionMatrix(testing$classe, predictRf)

accuracy <- postResample(predictRf, testing$classe); accuracy
oose <- 1 - as.numeric(confusionMatrix(testing$classe, predictRf)$overall[1])
oose
```
* Estimated accuracy: 98.96%  
* Estimated out-of-sample error: 1.03%  

```{r, cache = T}
treeModel <- rpart(classe ~ ., data=training, method="class")
prp(treeModel)
```

## Predicting for Test Data Set
```{r}
predictions <- predict(fit, newdata=testData)
# convert predictions to character vector
predictions <- as.character(predictions)
# create function to write predictions to files
pml_write_files <- function(x) {
    n <- length(x)
    for(i in 1:n) {
        filename <- paste0("problem_id_", i, ".txt")
        write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
    }
}

# create prediction files to submit
pml_write_files(predictions)
```